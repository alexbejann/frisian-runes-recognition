{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Convolutional Neural Networks\n",
    "\n",
    "Daniel-Alexandru Bejan (474404)\n",
    "Patrick Schaper (534366)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you are going to use the dataset IML-2022-Anglo-Saxion-Runes\n",
    "from Introduction to Machine Learning (see BlackBoard).\n",
    "\n",
    "There are plenty of examples of how to build convolutional neural networks. We advice\n",
    "you, however, to reuse the code from your first assignment. \n",
    "\n",
    "This time you also need to\n",
    "use convolutional layers and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, json, shutil, pprint\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def display(np_image):\n",
    "    \"\"\"\n",
    "    This is a display function that we have added to show numpy images at full size\n",
    "    If you pass in an image with 3 channels, it will be displayed in RGB\n",
    "    If you passn in an image with 1 channel, it will be displayed in grayscale\n",
    "    \"\"\"\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    if len(np_image.shape) == 3:\n",
    "        height, width, depth = np_image.shape\n",
    "    else:\n",
    "        height, width = np_image.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axis that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image in either RGB or grayscale (depending on the amount of dimensions)\n",
    "    if (len(np_image.shape) >= 3):\n",
    "        ax.imshow(np_image)\n",
    "    else:\n",
    "        ax.imshow(np_image, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 3030\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 128x128 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './MLBD-dataset-IML-2022-Anglo-Saxion-Runes'\n",
    "images_original = io.imread_collection(os.path.join(f'{path}/*.png'))\n",
    "print(f'Number of images: {len(images_original)}')\n",
    "display(images_original[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new dataframe with the labels and the image names separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_features = []\n",
    "\n",
    "for file_name in listdir(path):\n",
    "    full_path = join(path, file_name)\n",
    "    if isfile(full_path):\n",
    "        if re.match(r\".*\\.png$\", full_path):\n",
    "            image_label = file_name.split('_')[0].lower()\n",
    "            image_number = file_name.split('_')[2].lower() + \"_\" + file_name.split('_')[3].lower()\n",
    "\n",
    "            image_definition = [image_number, image_label]\n",
    "\n",
    "            images_with_features.append(image_definition)\n",
    "\n",
    "labeled_images = pd.DataFrame(images_with_features, columns=[\"rune_id\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rune_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160547_2025030270.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160547_2549270937.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160547_3669898631.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160547_4105113150.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160547_4272441664.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>160547_4538430006.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>160547_7060350912.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>160547_7724475204.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160547_8403188040.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>160547_9446549830.png</td>\n",
       "      <td>ash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rune_id label\n",
       "0  160547_2025030270.png   ash\n",
       "1  160547_2549270937.png   ash\n",
       "2  160547_3669898631.png   ash\n",
       "3  160547_4105113150.png   ash\n",
       "4  160547_4272441664.png   ash\n",
       "5  160547_4538430006.png   ash\n",
       "6  160547_7060350912.png   ash\n",
       "7  160547_7724475204.png   ash\n",
       "8  160547_8403188040.png   ash\n",
       "9  160547_9446549830.png   ash"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_images.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is stated into the the assignment we are going to experiment with different network structures. \n",
    "\n",
    "Therefore, we would have to:\n",
    "\n",
    "- Experiment with at least 6 different network structures with minimum of 2 convolutional layers per network.\n",
    "- Difference with and without dropout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "# BATCH_SIZE = 32\n",
    "IMG_SIZE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize digits from local fonts\n",
    "probabilities = model.predict(font_digits, steps=1)\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n",
    "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
    "\n",
    "# recognize validation digits\n",
    "probabilities = model.predict(validation_digits, steps=1)\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n",
    "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    return "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fca98ced75e3b70b02ac3b0fddc14254b9e3b048d240659196fc27e019c1f4a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
