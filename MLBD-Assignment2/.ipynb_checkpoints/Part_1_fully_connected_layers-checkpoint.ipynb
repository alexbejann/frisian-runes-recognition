{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Fully Connected Layers\n",
    "\n",
    "Daniel-Alexandru Bejan (474404)\n",
    "Patrick Schaper (534366)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided dataset contains possible combinations for the game Yathzee. If you don’t know the rules for this dice game, please have a look at: https://en.wikipedia.org/wiki/Yahtzee.\n",
    "\n",
    "Please note: the dataset is imbalanced. This means that you might need to balance it first\n",
    "before you will get good results! There a several possible solutions, please read: https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758 for a better understanding.\n",
    "\n",
    "You will need to build a neural network that is able to predict the label for 5 thrown dice. The available labels are mentioned in the table below.\n",
    "\n",
    "- 3-of-a-kind: Three dice the same.\n",
    "- 4-of-a-kind: Four dice the same.\n",
    "- Full-house: Three of one number and two of another\n",
    "- small-straight Four sequential dice: (1-2-3-4, 2-3-4-5, or 3-4-5-6)\n",
    "- Large-straight Five sequential dice: (1-2-3-4-5 or 2-3-4-5-6)\n",
    "- Yathzee: All five dice the same\n",
    "- Nothing: None of the above combinations has been thrown\n",
    "\n",
    "**Goal of the assignment**\n",
    "\n",
    "The overall goal is to experiment with deep learning and find out what gives you the\n",
    "best results. Don’t forget to compare the results and write a conclusion!\n",
    "Experiments we expect you to carry out:\n",
    "- Playing around with different networks sizes\n",
    " - Different number of layers\n",
    " - Different number of neurons per layer\n",
    " - At least 6 different networks with a minimum of 1 hidden layer per network\n",
    "- Comparison of different activation functions:\n",
    " - Sigmoid\n",
    " - Tanh\n",
    " - ReLu\n",
    "- Difference with and without dropout.\n",
    "\n",
    "The notebook should contain:\n",
    "- For each neural network that you train: graphs from TensorBoard or Matplotlib showing the accuracy and the loss for train set and validation set and the accuracy scores for the test set.\n",
    "- Your observations and conclusions per network (and graph)!\n",
    "- An export of your best trained network and a way to run this exported model.\n",
    "\n",
    "**Hints**\n",
    "\n",
    "In order to build proper neural networks, keep in mind:\n",
    "- Convert the labels into one-hot-encoded values.\n",
    "- Use cross-entropy as loss function for classification.\n",
    "- Create a proper output layer that uses SoftMax activation.\n",
    "- Use the accuracy metric to measure your classification performance.\n",
    "- Avoid overfitting by using dropout, a test set (which you use in the end) and cross validation.\n",
    "\n",
    "Export your best model and add a cell to your notebook that loads the model and is\n",
    "able to validate your model, by loading in a dataset from file and feeding it into the\n",
    "network. This cell should show the accuracy of the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dice1</th>\n",
       "      <th>dice2</th>\n",
       "      <th>dice3</th>\n",
       "      <th>dice4</th>\n",
       "      <th>dice5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>small-straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dice1  dice2  dice3  dice4  dice5           label\n",
       "0      3      6      6      2      5         nothing\n",
       "1      3      6      1      3      4         nothing\n",
       "2      2      2      5      5      3         nothing\n",
       "3      1      3      6      6      1         nothing\n",
       "4      1      4      6      3      5  small-straight"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_df = pd.read_csv('MLBD-dataset-yahtzee.csv')\n",
    "raw_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5832 entries, 0 to 5831\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   dice1   5832 non-null   int64 \n",
      " 1   dice2   5832 non-null   int64 \n",
      " 2   dice3   5832 non-null   int64 \n",
      " 3   dice4   5832 non-null   int64 \n",
      " 4   dice5   5832 non-null   int64 \n",
      " 5   label   5832 non-null   object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 273.5+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "four-of-a-kind      116\n",
       "full-house          221\n",
       "large-straight      178\n",
       "nothing            3868\n",
       "small-straight      549\n",
       "three-of-a-kind     896\n",
       "yathzee               4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.groupby(['label'])['label'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First result of analysing\n",
    "\n",
    "We see a very unbalanced data set. One rubric stands out particularly strongly. The number of \"yathzee's\" is just 4. According to the rules of the game, a \"yathzee\" occurs when all dice show the same number. So we add the missing records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dice1</th>\n",
       "      <th>dice2</th>\n",
       "      <th>dice3</th>\n",
       "      <th>dice4</th>\n",
       "      <th>dice5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>yathzee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yathzee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>yathzee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>yathzee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dice1  dice2  dice3  dice4  dice5    label\n",
       "1101      5      5      5      5      5  yathzee\n",
       "1180      2      2      2      2      2  yathzee\n",
       "1602      6      6      6      6      6  yathzee\n",
       "5504      3      3      3      3      3  yathzee"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['label'] == 'yathzee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()\n",
    "\n",
    "df.loc[len(df.index)] = [1,1,1,1,1,'yathzee']\n",
    "df.loc[len(df.index)] = [4,4,4,4,4,'yathzee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=3868 (66.301%)\n",
      "Class=1, n=549 (9.410%)\n",
      "Class=2, n=896 (15.358%)\n",
      "Class=3, n=178 (3.051%)\n",
      "Class=4, n=221 (3.788%)\n",
      "Class=5, n=116 (1.988%)\n",
      "Class=6, n=6 (0.103%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_labels = df.label.unique()\n",
    "df.label = pd.factorize(df.label)[0]\n",
    "\n",
    "features = []\n",
    "for feature in df.columns:\n",
    "    if feature != 'label':\n",
    "        features.append(feature)\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "counter = Counter(y_encoded)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    \n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6]),\n",
       " array([3065,  443,  740,  143,  173,   98,    5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "n_samples = int(round(np.unique(y_train, return_counts=True)[1].mean()))\n",
    "\n",
    "def sampling_strategy(X, y, n_samples, t='majority'):\n",
    "    target_classes = ''\n",
    "    if t == 'majority':\n",
    "        target_classes = y.value_counts() > n_samples\n",
    "    elif t == 'minority':\n",
    "        target_classes = y.value_counts() < n_samples\n",
    "    tc = target_classes[target_classes == True].index\n",
    "    #target_classes_all = y.value_counts().index\n",
    "    sampling_strategy = {}\n",
    "    for target in tc:\n",
    "        sampling_strategy[target] = n_samples\n",
    "    return sampling_strategy\n",
    "\n",
    "under_sampler = ClusterCentroids(sampling_strategy=sampling_strategy(X_train, y_train, n_samples, t='majority'), random_state=1337)\n",
    "X_under, y_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "over_sampler = SMOTE(sampling_strategy=sampling_strategy(X_under, y_under, n_samples, t='minority'), k_neighbors=2, random_state=1337)\n",
    "\n",
    "X_bal, y_bal = over_sampler.fit_resample(X_under, y_under)\n",
    "\n",
    "count = y_bal.value_counts()\n",
    "count.plot.bar()\n",
    "plt.ylabel('Number of records')\n",
    "plt.xlabel('Target Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6]),\n",
       " array([3022, 3065, 3065, 3065, 3065, 3065, 3065]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "resample = SMOTETomek(random_state=1337, tomek=TomekLinks(sampling_strategy='majority'), smote=SMOTE(k_neighbors=3))\n",
    "X_bal, y_bal = resample.fit_resample(X_train, y_train)\n",
    "\n",
    "np.unique(y_bal, return_counts=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Min-Max-Skalierungs-Transformer erstellen\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the transformer on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_bal = X_train\n",
    "y_bal = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 16:16:06.158369: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, Nadam\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization, Normalization\n",
    "from keras.callbacks import History\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 16:16:07.932357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "normalizer = keras.layers.Normalization()\n",
    "normalizer.adapt(X_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluat_my_model(model, input_data, output_data):\n",
    "    \n",
    "    output_data = output_data.values.reshape(-1,1)\n",
    "    output_data = tf.keras.utils.to_categorical(output_data, np.unique(output_data).size)\n",
    "    \n",
    "    evaluation_results = model.evaluate(input_data, output_data)\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "def create_model(input_data, output_data, layers=[], optimizer=\"adam\", endActi=\"softmax\"):\n",
    "    \n",
    "    learningRate = 0.001\n",
    "    \n",
    "    inputNeurons = input_data.shape[1]\n",
    "    outputNeurons = np.unique(output_data).size\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    firstLayer = True\n",
    "    \n",
    "    for layer in layers:\n",
    "        if(firstLayer):\n",
    "            model.add(Dense(layer[0], input_shape=(inputNeurons,), activation=layer[1]))\n",
    "            firstLayer = False\n",
    "        else:\n",
    "            model.add(Dense(layer[0], activation=layer[1]))\n",
    "            \n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        if(2 < len(layer)):\n",
    "            model.add(Dropout(layer[2]))\n",
    "    \n",
    "    model.add(Dense(outputNeurons, activation=endActi))\n",
    "    \n",
    "    if optimizer == \"adam\":\n",
    "        opti = Adam(learning_rate=learningRate)\n",
    "    elif optimizer == \"nadam\":\n",
    "        opti = Nadam(learning_rate=learningRate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        opti = SGD(learning_rate=learningRate)\n",
    "    elif optimizer == \"adagrad\":\n",
    "        opti = Adagrad(learning_rate=learningRate)\n",
    "    else:\n",
    "        opti = optimizer\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opti, metrics=[\"accuracy\"], sample_weight_mode=\"temporary\",)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_fit_model(input_data, output_data, layers=[], optimizer=\"adam\", endActi=\"softmax\", batchSize=50, epochs=100, verbose=0, withHistory=0):\n",
    "        \n",
    "        model = create_model(input_data, output_data, layers, optimizer=optimizer, endActi=endActi)\n",
    "    \n",
    "        #class_weights = class_weight.compute_class_weight( class_weight = \"balanced\", classes = np.unique(y_bal), y = y_bal)\n",
    "    \n",
    "        inputNeurons = input_data.shape[1]\n",
    "        outputNeurons = np.unique(output_data).size\n",
    "\n",
    "        output_data = output_data.values.reshape(-1,1)\n",
    "        output_data = tf.keras.utils.to_categorical(output_data, outputNeurons)\n",
    "        y_test_cat = tf.keras.utils.to_categorical(y_test, outputNeurons)\n",
    "        \n",
    "        history = History()\n",
    "        history = model.fit(x=input_data, y=output_data, batch_size=batchSize, epochs=epochs, verbose=verbose, shuffle=True, validation_split=0.2, callbacks=[history])\n",
    "        evaluate = evaluat_my_model(model=model, input_data=X_test, output_data=y_test)\n",
    "        models.append({\n",
    "            'layers':layers,\n",
    "            'optimizer':optimizer,\n",
    "            'batchSize':batchSize,\n",
    "            'epochs':epochs,\n",
    "            'endActi':endActi,\n",
    "            'loss':history['loss'],\n",
    "            'accuracy':history['accuracy'],\n",
    "            'val_accuracy':history['val_accuracy']\n",
    "            })\n",
    "        \n",
    "        if withHistory == 1:\n",
    "            return model, history\n",
    "        return model\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"relu\",0.2),\n",
    "            (130,\"relu\",0.2),\n",
    "         (80,\"relu\",0.2)]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"adam\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"relu\",0.2),\n",
    "            (130,\"relu\",0.2),\n",
    "         (80,\"relu\",0.2)]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"adagrad\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"relu\",0.2),\n",
    "            (130,\"relu\",0.2),\n",
    "         (80,\"relu\",0.2)]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"sgd\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"sigmoid\",0.2),\n",
    "            (130,\"relu\",0.2),\n",
    "         (80,\"relu\",0.2)]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"sgd\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"tanh\",0.2),\n",
    "            (130,\"relu\",0.2),\n",
    "         (80,\"relu\",0.2)]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"sgd\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"sigmoid\"),\n",
    "            (130,\"relu\"),\n",
    "         (80,\"relu\")]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"adam\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"relu\"),\n",
    "          (210,\"sigmoid\")]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"adam\", endActi=\"softmax\", batchSize=10, epochs=50, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(50,\"relu\"),\n",
    "            (25,\"relu\",0.2),\n",
    "         (10,\"sigmoid\",0.3),\n",
    "         (5,\"relu\",0.2)]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"sgd\", endActi=\"softmax\", batchSize=16, epochs=100, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [(300,\"tanh\"),\n",
    "         (170,\"tanh\"),\n",
    "         (100,\"tanh\")]\n",
    "model, history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=\"nadam\", endActi=\"softmax\", batchSize=16, epochs=100, verbose=0, withHistory=1)\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_acc_model():\n",
    "    bestItem = max(models, key=lambda x:x['accuracy'])\n",
    "    return bestItem\n",
    "def get_best_loss_model():\n",
    "    bestItem = min(models, key=lambda x:x['loss'])\n",
    "    return bestItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = get_best_acc_model()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = best_model['layers']\n",
    "model,history = create_fit_model(input_data=X_bal, output_data=y_bal, layers=layers, optimizer=best_model['optimizer'], endActi=best_model['endActi'], batchSize=best_model['batchSize'], epochs=best_model['epochs'], verbose=0, withHistory=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_model')\n",
    "model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def analyse_my_mode(model, history):\n",
    "    model.summary()\n",
    "    print(\"\\n\")\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    y_pred = (predictions > 0.5)\n",
    "    y_test_=y_test.astype(int).tolist()\n",
    "    print(confusion_matrix(y_test_, y_pred.argmax(axis=1)))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_true=y_test_,y_pred=y_pred.argmax(axis=1), target_names=y_labels,zero_division=0))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    plot_acc_loss(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_my_mode(model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cs231n.github.io/assets/nn3/learningrates.jpeg\">\n",
    "(Effect of Learning rate on Loss (Source: CS231n Convolutional Neural Networks for Visual Recognition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(diceOne, diceTwo, diceThree, diceFour, diceFive, printResult=False):\n",
    "    _ = model.predict([[diceOne, diceTwo, diceThree, diceFour, diceFive]], verbose=0)\n",
    "    \n",
    "    if printResult:\n",
    "        return _\n",
    "    \n",
    "    result = y_labels[np.argmax(_, axis=1)[0]]\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result(2,2,2,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(7), fontsize=10)\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(y_labels, predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "prediction = model.predict([[1, 3, 2, 4, 3]], verbose=0)\n",
    "plot_value_array(i, prediction[i], [1]) #small-straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic from: https://www.tensorflow.org/tutorials/keras/classification\n",
    "def plot_bars(num_rows=5, num_cols=3):\n",
    "    predictions = model.predict(X_test)\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(2*2*num_cols, 3*num_rows))\n",
    "    for i in range(num_images):\n",
    "      plt.subplot(num_rows, num_cols, i+1)\n",
    "      plot_value_array(i, predictions[i], y_test.reset_index(drop=True))\n",
    "      if type(X_bal) is not np.ndarray:\n",
    "          dices = np.array(X_test.reset_index(drop=True))[i]\n",
    "      else:\n",
    "          dices = np.array(X_test)[i].astype(int)\n",
    "      title = str(dices[0]) + \",\" + str(dices[1]) + \",\" + str(dices[2]) + \",\" + str(dices[3]) + \",\" + str(dices[4])\n",
    "      plt.title(title)\n",
    "      plt.subplots_adjust(hspace=1.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fca98ced75e3b70b02ac3b0fddc14254b9e3b048d240659196fc27e019c1f4a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
