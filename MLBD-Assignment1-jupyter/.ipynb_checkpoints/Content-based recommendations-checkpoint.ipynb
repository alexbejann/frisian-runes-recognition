{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based recommendations\n",
    "- Daniel-Alexandru Bejan (474404)\n",
    "- Patrick Schaper (534366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from movie_display import movie_display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of showing movie information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies into a dataframe\n",
    "df = pd.read_json('./dataset/imdbdata.json', orient='columns')\n",
    "\n",
    "# Display information about some movies\n",
    "HTML(movie_display.show([df.iloc[0], df.iloc[1], df.iloc[2], df.iloc[3], df.iloc[4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set has 9125 entries and 18 features. Next, we look at the data type of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Filtering\n",
    "*During our research on the Internet we found the following [link](https://www.kaggle.com/code/yadukaggle/demographic-filtering-recommendation). Here, as a first recommendation, a demographic filtering based on the formula of IMDB was shown. Even though this was not part of our task, we found the approach good and applied it to our data.*\n",
    "\n",
    "For the first step of the recommendation, we use the rating of each film. However, there is a challenge with this. We need a metric for rating movies. We can use the average rating of the movie as a score, but that would not be fair because a movie with an average rating of 9.5 and only 5 votes cannot be considered better than a movie with an average rating of 7.9 and 55 votes. Therefore, we will use the weighted rating (wr) from IMDB, which is given as follows:\n",
    "\n",
    "$$Weighted Rating(WR) = (\\frac{v}{v+m}*R)+(\\frac{m}{v+m}*C)$$\n",
    "\n",
    "- v is the number of votes for the movie (imdbVotes)\n",
    "- m is the minimum votes required to be listed in the chart;\n",
    "- R is the average rating of the movie (imdbRating)\n",
    "- C is the mean vote across the whole report (df['imdbRating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some movies are not rated and there is a \"N/A\" in the column or use a comma as separator we still need to convert this to 0 and remove the divider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imdbRating'] = df['imdbRating'].str.replace('N/A','0')\n",
    "df['imdbVotes'] = df['imdbVotes'].str.replace('N/A','0')\n",
    "df['imdbVotes'] = df['imdbVotes'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = pd.to_numeric(df['imdbRating']).mean()\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean value is therefore 6.7 on a scale that goes up to 10. Next, \"m\" must be defined. m is the minimum number of ratings to be relevant for a recommendation at all. We will use the 80th percentile as the cutoff. This means: for a movie to be included in the hit list, it must have more votes than at least 80% of the movies in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.to_numeric(df['imdbVotes']).quantile(0.8)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualify_movies = df.copy().loc[pd.to_numeric(df['imdbVotes']) >= m]\n",
    "qualify_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that only 1825 films made it to the list of qualifying films. Now we need to calculate our metric for each qualified movie. To do this, we define a function, weighted_rating():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = pd.to_numeric(x['imdbVotes'])\n",
    "    R = pd.to_numeric(x['imdbRating'])\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualify_movies['imdbCalculatedScore'] = qualify_movies.apply(weighted_rating, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort movies\n",
    "qualify_movies = qualify_movies.sort_values('imdbCalculatedScore', ascending=False)\n",
    "\n",
    "#Print the top 15 movies\n",
    "qualify_movies[['Title', 'imdbVotes', 'imdbRating', 'imdbCalculatedScore']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a first recommendation on the rating of all users. Next is a rating based on the preference of a single movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Filtering\n",
    "Next, we come to the actual task of this assessment. The content based filtering/recommendation. \n",
    "\n",
    "The requirement was to include only the \"Plot\" and \"Writer\" columns, however we felt the \"Title\" was just as important. You will see the reason for this later. However, we always focus on \"Plot\" and \"Writer\" first. The \"Title\" column always follows as an addition. \n",
    "\n",
    "The first step is to select only the required columns and copy them into a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = df.loc[:, ['imdbId','Title','Plot','Writer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "For clean processing we first prepare the texts by removing unnecessary strings and eliminating upper and lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_df['Writer'] = movie_df['Writer'].str.replace(r' \\([^)]*\\)', '', regex=True)\n",
    "movie_df['Writer'] = movie_df['Writer'].str.replace(r'\\s+', '',regex=True)\n",
    "movie_df['Writer'] = movie_df['Writer'].str.replace(r',', ', ',regex=True)\n",
    "movie_df['Writer'] = movie_df['Writer'].str.lower()\n",
    "\n",
    "movie_df['Plot'] = movie_df['Plot'].str.lower()\n",
    "\n",
    "movie_df['Title'] = movie_df['Title'].str.lower()\n",
    "\n",
    "movie_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we eliminate morphological and inflexional endings with **Snowball Stemmer**. Snowball Stemmer is also known as the Porter2 stemming algorithm because it is a better version of the Porter Stemmer. It is more aggressive than Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "ss = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y=[]\n",
    "    for i in text.split():\n",
    "        y.append(ss.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_df['Plot'] = movie_df['Plot'].apply(stem)\n",
    "movie_df['Writer'] = movie_df['Writer'].apply(stem)\n",
    "movie_df['Title'] = movie_df['Title'].apply(stem)\n",
    "\n",
    "movie_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words to numbers\n",
    "\n",
    "We start with the CountVectorizer. This converts a collection of text documententen to a matrix of token counts. Note that we use the \"Stopword\" function to exclude unnecessary words that occur frequently, such as \"a\" or \"of\".\n",
    "\n",
    "At this point, let's first look at the \"Plot\" and \"Writer\" columns. The editing for the \"Title\" will follow later but according to the same procedure.\n",
    "\n",
    "Hint:\n",
    "- Bag of Words (BOW): Converting words to numbers with no semantic information.\n",
    "- TF-IDF: It is also converting the words to numbers or vectors with some weighted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv_plot = CountVectorizer(analyzer='word', stop_words='english')\n",
    "cv_writer = CountVectorizer(analyzer='word', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_plot.fit_transform(movie_df['Plot']).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_writer.fit_transform(movie_df['Writer']).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = cv_plot.fit_transform(movie_df['Plot']).toarray()\n",
    "print(\"BOW Matrix Plot:\")\n",
    "pd.DataFrame(X_plot[0:20,400:500], columns=cv_plot.get_feature_names_out()[400:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have created our \"bag on words\" we check the whole thing. To do this, we display the 10 records again and check the words from 400-500. For example, we see that the 7th record contains the word \"accu\" once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_writer = cv_writer.fit_transform(movie_df['Writer']).toarray()\n",
    "print(\"BOW Matrix Writer:\")\n",
    "pd.DataFrame(X_writer[0:20,200:300], columns=cv_writer.get_feature_names_out()[200:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach to turn words into Numbers is to use TF-IDF. Works similarly, but still brings a weighting of the words. The important thing is that we use the transformer, so we work on the result of BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "cv_plot_tfidf = TfidfTransformer()\n",
    "cv_writer_tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot_tfidf = cv_plot_tfidf.fit_transform(X_plot).toarray()\n",
    "print(\"TFIDF Matrix Plot:\")\n",
    "pd.DataFrame(X_plot_tfidf[0:20,400:500], columns=cv_plot.get_feature_names_out()[400:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_writer_tfidf = cv_writer_tfidf.fit_transform(X_writer).toarray()\n",
    "print(\"TFIDF Matrix Writer:\")\n",
    "pd.DataFrame(X_writer_tfidf[0:20,200:300], columns=cv_writer.get_feature_names_out()[200:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities and differences using the Cosine Simultary\n",
    "\n",
    "Now that we know which words appear where and how often, we can use cosines to calculate which movies have more similar text content and which do not. This happens for Bag of words (BOW) and for the TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_plot_bow = cosine_similarity(X_plot)\n",
    "cosine_plot_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_plot_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_writer_bow = cosine_similarity(X_writer)\n",
    "cosine_writer_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_writer_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_plot_tf = cosine_similarity(X_plot_tfidf)\n",
    "cosine_plot_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_plot_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_writer_tf = cosine_similarity(X_writer_tfidf)\n",
    "cosine_writer_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_plot_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What movies are similar...\n",
    "\n",
    "Now we have everything we need to make a recommendation based on Plot or Writer. For this we have written a function that returns a recommendation based on a movie\n",
    "\n",
    "Addition: This function has grown during the working process and some functionalities have been added which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(movieIndex, cosine, output=\"print\", number_of_recommendations=6, movie_count=1):\n",
    "    distance = cosine[movieIndex]\n",
    "    movie_list = sorted(list(enumerate(distance)), reverse=True, key=lambda x:x[1])[movie_count:number_of_recommendations+1] #start by 1 because 0 is the element self\n",
    "    \n",
    "    if output == \"print\":\n",
    "        for i in movie_list:\n",
    "            print(f'{df.iloc[i[0]].Title:{30}} {i[1]:{20}}')\n",
    "        print(\"-\"*50)\n",
    "    if output == \"tupel\":\n",
    "        back = []\n",
    "        for i in movie_list:\n",
    "            back.append((df.iloc[i[0]].Title,i[1]))\n",
    "        return back\n",
    "    if output == \"titles\":\n",
    "        back = []\n",
    "        for i in movie_list:\n",
    "            back.append(df.iloc[i[0]].Title)\n",
    "        return back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better compare our results, we now set a movie for the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMovieId = 0 # Toy Story\n",
    "#testMovieId = 6916 # The Dark Knight\n",
    "HTML(movie_display.show([df.iloc[testMovieId]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are our different cosine values for our test film?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation(testMovieId,cosine_plot_tf)\n",
    "recommendation(testMovieId,cosine_plot_bow)\n",
    "recommendation(testMovieId,cosine_writer_tf)\n",
    "recommendation(testMovieId,cosine_writer_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test film, we first had the children's film \"Toy Story\". As a recommendation, we got a horror movie called \"Chuck the Killer Doll\" based on the plot. And this although there are \"Toy Story 2\" and \"Toy Story 3\". For this reason, we decided to include the title. \n",
    "\n",
    "But by the way, this was funny result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_title = CountVectorizer(analyzer='word', stop_words='english')\n",
    "cv_title.fit_transform(movie_df['Title']).toarray().shape\n",
    "X_title = cv_title.fit_transform(movie_df['Title']).toarray()\n",
    "\n",
    "cv_title_tfidf = TfidfTransformer()\n",
    "X_title_tfidf = cv_title_tfidf.fit_transform(X_title).toarray()\n",
    "cosine_title_bow = cosine_similarity(X_title)\n",
    "cosine_title_tf = cosine_similarity(X_title_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation(testMovieId,cosine_plot_tf)\n",
    "recommendation(testMovieId,cosine_plot_bow)\n",
    "recommendation(testMovieId,cosine_writer_tf)\n",
    "recommendation(testMovieId,cosine_writer_bow)\n",
    "recommendation(testMovieId,cosine_title_tf)\n",
    "recommendation(testMovieId,cosine_title_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better result presentation we wrote a small function that shows us the movies in HTML based on the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMovieInHtml(names=[]):\n",
    "    movies = []\n",
    "    for x in range(len(names)):\n",
    "        movieIndex = df.loc[df['Title'] == names[x]].index[0]\n",
    "        movies.append(df.iloc[movieIndex])\n",
    "    return HTML(movie_display.show(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot tfidf:')\n",
    "showMovieInHtml(recommendation(testMovieId,cosine_plot_tf,\"titles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot bow:')\n",
    "showMovieInHtml(recommendation(testMovieId,cosine_plot_bow,\"titles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writer tfidf:')\n",
    "showMovieInHtml(recommendation(testMovieId,cosine_writer_tf,\"titles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writer bow:')\n",
    "showMovieInHtml(recommendation(testMovieId,cosine_writer_bow,\"titles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Title tfidf:')\n",
    "showMovieInHtml(recommendation(testMovieId,cosine_title_tf,\"titles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Title bow:')\n",
    "showMovieInHtml(recommendation(testMovieId,cosine_title_bow,\"titles\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only the best of the best\n",
    "\n",
    "In order to create a clear list of the best films, we have decided to take the first approach, which is to simply take the films with the best value. Regardless of whether with BOW or TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_list(movieId, unique=True, number_of_recommendations=6):\n",
    "    top_list = recommendation(movieId,cosine_plot_tf,'tupel',number_of_recommendations) + \\\n",
    "        recommendation(movieId,cosine_plot_bow,'tupel',number_of_recommendations) + \\\n",
    "        recommendation(movieId,cosine_writer_tf,'tupel',number_of_recommendations) + \\\n",
    "        recommendation(movieId,cosine_writer_bow,'tupel',number_of_recommendations) + \\\n",
    "        recommendation(movieId,cosine_title_tf,'tupel',number_of_recommendations) + \\\n",
    "        recommendation(movieId,cosine_title_bow,'tupel',number_of_recommendations)\n",
    "    top_list = sorted(top_list, key=lambda x: x[1], reverse=True)\n",
    "    if unique==False:\n",
    "        return top_list\n",
    "    else:\n",
    "        titles = []\n",
    "        back = []\n",
    "        for movie in top_list:\n",
    "            if movie[0] not in titles:\n",
    "                titles.append(movie[0])\n",
    "                back.append(movie)\n",
    "        return back[:number_of_recommendations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie_top_list = get_top_list(testMovieId, False)\n",
    "for movie in test_movie_top_list:\n",
    "    print(f'{movie[0]:<{50}} {movie[1]:<{30}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie_top_list = get_top_list(testMovieId)\n",
    "for movie in test_movie_top_list:\n",
    "    print(f'{movie[0]:<{50}} {movie[1]:<{30}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie_top_list = get_top_list(testMovieId,True)\n",
    "test_movie_titles = []\n",
    "for movie in test_movie_top_list:\n",
    "    test_movie_titles.append(movie[0])\n",
    "\n",
    "showMovieInHtml(test_movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another approach\n",
    "\n",
    "Another approach to making recommendations was to add the cosine similarities. This has the advantage that we can add a weighting to the individual columns. For example, we can say that the title is considered twice or something similar. So that this task does not explode however the framework, we set the weight everywhere on 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_cosine_sum(array_cosines):\n",
    "    sum = np.array(0)\n",
    "    for cos in array_cosines:\n",
    "        sum = np.add(sum, cos * 1)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie_consine_sum = calculate_cosine_sum([cosine_plot_tf, cosine_plot_bow, cosine_writer_tf, cosine_writer_bow, cosine_title_tf, cosine_title_bow])\n",
    "\n",
    "recommendation(testMovieId, test_movie_consine_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_list_from_sum(movieId, consine_sum, number_of_recommendations=6):\n",
    "    top_list = recommendation(movieId, consine_sum, 'tupel', number_of_recommendations)\n",
    "    top_list = sorted(top_list, key=lambda x: x[1], reverse=True)\n",
    "    titles = []\n",
    "    back = []\n",
    "    for movie in top_list:\n",
    "        if movie[0] not in titles:\n",
    "            titles.append(movie[0])\n",
    "            back.append(movie)\n",
    "    return back[:number_of_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation based on one movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sum_for_one = np.array(0)\n",
    "\n",
    "selected_movie_for_one = widgets.Dropdown(\n",
    "    options=list(zip(df.Title, df.index)),\n",
    "    description='Select a movie:\\n ',\n",
    "    disabled=False,\n",
    "    layout={'width': 'max-content'}\n",
    ")\n",
    "recommendations_for_one = widgets.IntText(\n",
    "    min=0,\n",
    "    value=3,\n",
    "    description='Number of recommendations:\\n ',\n",
    "    disabled=False\n",
    ")\n",
    "merge_strategy_for_one = widgets.RadioButtons(\n",
    "    options=[('Each matrix by itself',0), ('Sum matrix',1)],\n",
    "    description='Merge strategy:',\n",
    "    disabled=False\n",
    ")\n",
    "button_for_one = widgets.Button(\n",
    "    description='Recommendation',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def execute_function_for_one(_):\n",
    "    global cosine_sum_for_one\n",
    "    with out_for_one:\n",
    "          clear_output()\n",
    "          recommendation_titles = []\n",
    "        \n",
    "          if merge_strategy_for_one.value == 0:\n",
    "              recommendation_list = get_top_list(selected_movie_for_one.value, True, recommendations_for_one.value)\n",
    "          if merge_strategy_for_one.value == 1:\n",
    "              if cosine_sum_for_one.size == 1:\n",
    "                  cosine_sum_for_one = calculate_cosine_sum([cosine_plot_tf, cosine_plot_bow, cosine_writer_tf, cosine_writer_bow, cosine_title_tf, cosine_title_bow])\n",
    "              recommendation_list = get_top_list_from_sum(selected_movie_for_one.value, cosine_sum_for_one, recommendations_for_one.value)\n",
    "          \n",
    "          for movie in recommendation_list:\n",
    "            recommendation_titles.append(movie[0])\n",
    "            \n",
    "          print(\"Selected Movie:\")\n",
    "          display(HTML(movie_display.show([df.iloc[selected_movie_for_one.value]])))\n",
    "            \n",
    "          print(\"Recommendation(s):\")\n",
    "          display(showMovieInHtml(recommendation_titles))\n",
    "            \n",
    "button_for_one.on_click(execute_function_for_one)\n",
    "out_for_one = widgets.Output()\n",
    "\n",
    "box_for_one = widgets.VBox([selected_movie_for_one, recommendations_for_one, merge_strategy_for_one, button_for_one, out_for_one])\n",
    "box_for_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation based on multiple movies - First approach!\n",
    "\n",
    "Next, we tried to implement the recommendation based on several films. The first idea was to create an \"own\" film from the selected films. This means that the selected movies are merged together before the cosine calculation takes place.\n",
    "\n",
    "You can see a copy-and-paste prototype that performs a new cosine calculation each time. Since we have found that this is very computationally expensive and therefore not a practical solution, we left it at the prototype. For this reason there are no different merge strategies. \n",
    "\n",
    "Be careful when using it! It works, but may take a little while and may crash the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_movies_for_more = []\n",
    "multi_movie_df = movie_df[['Title','Plot','Writer']]\n",
    "\n",
    "movies_for_more = widgets.Dropdown(\n",
    "    options=list(zip(df.Title, df.index)),\n",
    "    description='Select a movie:\\n ',\n",
    "    disabled=False,\n",
    "    layout={'width': 'max-content'}\n",
    ")\n",
    "button_add_for_more = widgets.Button(\n",
    "    description='Add movie',\n",
    "    disabled=False,\n",
    ")\n",
    "button_remove_all_for_more = widgets.Button(\n",
    "    description='Delete all selected movies',\n",
    "    disabled=False,\n",
    ")\n",
    "recommendations_for_more = widgets.IntText(\n",
    "    min=0,\n",
    "    value=3,\n",
    "    description='Number of recommendations:\\n ',\n",
    "    disabled=False\n",
    ")\n",
    "button_recommendation_for_more = widgets.Button(\n",
    "    description='Recommendation',\n",
    "    disabled=False,\n",
    ")\n",
    "def execute_function_add_for_more(_):\n",
    "    with out_add_for_more:\n",
    "        clear_output()\n",
    "        if not movies_for_more.value in selected_movies_for_more:\n",
    "            selected_movies_for_more.append(movies_for_more.value)\n",
    "        movies_df_for_more = []\n",
    "        for movie in selected_movies_for_more:\n",
    "            movies_df_for_more.append(df.iloc[movie])\n",
    "        print(\"Selected Movie(s):\")\n",
    "        display(HTML(movie_display.show(movies_df_for_more)))\n",
    "\n",
    "def execute_function_remove_all_for_more(_):\n",
    "    with out_add_for_more:\n",
    "        clear_output()\n",
    "        selected_movies_for_more.clear()\n",
    "        \n",
    "def merge_movies():\n",
    "  multi_title = ''\n",
    "  multi_plot = ''\n",
    "  multi_writer = ''\n",
    "  selected_movies_for_more.sort()\n",
    "  for movieId in selected_movies_for_more:\n",
    "      multi_title += ' ' + multi_movie_df.iloc[movieId]['Title']\n",
    "      multi_plot += ' ' + multi_movie_df.iloc[movieId]['Plot']\n",
    "      multi_writer += ' ' + multi_movie_df.iloc[movieId]['Writer']\n",
    "  new_multi_movi = [multi_title, multi_plot, multi_writer]\n",
    "  multi_movie_df.loc[len(multi_movie_df)] = new_multi_movi\n",
    "  multi_movie_df.drop(selected_movies_for_more, 0, inplace=True)\n",
    "  #print(len(multi_movie_df))\n",
    "\n",
    "def create_cosine():\n",
    "    pass\n",
    "    \n",
    "def get_top_list_for_more(movieId, unique=True, number_of_recommendations=6):\n",
    "    cv_title_multi = CountVectorizer(analyzer='word', stop_words='english')\n",
    "    cv_plot_multi = CountVectorizer(analyzer='word', stop_words='english')\n",
    "    cv_writer_multi = CountVectorizer(analyzer='word', stop_words='english')\n",
    "    \n",
    "    cv_title_tfidf_multi = TfidfTransformer()\n",
    "    cv_plot_tfidf_multi = TfidfTransformer()\n",
    "    cv_writer_tfidf_multi = TfidfTransformer()\n",
    "    \n",
    "    X_title_multi = cv_title_multi.fit_transform(multi_movie_df['Title']).toarray()\n",
    "    X_plot_multi = cv_plot_multi.fit_transform(multi_movie_df['Plot']).toarray()\n",
    "    X_writer_multi = cv_writer_multi.fit_transform(multi_movie_df['Writer']).toarray()\n",
    "    \n",
    "    X_title_tfidf_multi = cv_title_tfidf_multi.fit_transform(X_title_multi).toarray()\n",
    "    X_plot_tfidf_multi = cv_plot_tfidf_multi.fit_transform(X_plot_multi).toarray()\n",
    "    X_writer_tfidf_multi = cv_writer_tfidf_multi.fit_transform(X_writer_multi).toarray()\n",
    "    \n",
    "    cosine_title_tf_multi = cosine_similarity(X_plot_tfidf_multi)\n",
    "    cosine_plot_tf_multi = cosine_similarity(X_plot_tfidf_multi)\n",
    "    cosine_writer_tf_multi = cosine_similarity(X_plot_tfidf_multi)\n",
    "    \n",
    "    cosine_title_bow_multi = cosine_similarity(X_title_multi)\n",
    "    cosine_plot_bow_multi = cosine_similarity(X_plot_multi)\n",
    "    cosine_writer_bow_multi = cosine_similarity(X_writer_multi)\n",
    "    \n",
    "    print(\"Cosine done\")\n",
    "    \n",
    "    top_list_for_more = recommendation(movieId,cosine_plot_tf_multi,'tupel',number_of_recommendations, len(selected_movies_for_more)) + \\\n",
    "        recommendation(movieId,cosine_plot_bow_multi,'tupel',number_of_recommendations, len(selected_movies_for_more)) + \\\n",
    "        recommendation(movieId,cosine_writer_tf_multi,'tupel',number_of_recommendations, len(selected_movies_for_more)) + \\\n",
    "        recommendation(movieId,cosine_writer_bow_multi,'tupel',number_of_recommendations, len(selected_movies_for_more)) + \\\n",
    "        recommendation(movieId,cosine_title_tf_multi,'tupel',number_of_recommendations, len(selected_movies_for_more)) + \\\n",
    "        recommendation(movieId,cosine_title_bow_multi,'tupel',number_of_recommendations, len(selected_movies_for_more))\n",
    "    top_list_for_more = sorted(top_list_for_more, key=lambda x: x[1], reverse=True)\n",
    "    if unique==False:\n",
    "        return top_list_for_more\n",
    "    else:\n",
    "        titles = []\n",
    "        back = []\n",
    "        for movie in top_list_for_more:\n",
    "            if movie[0] not in titles:\n",
    "                titles.append(movie[0])\n",
    "                back.append(movie)\n",
    "        return back[:number_of_recommendations]\n",
    "    \n",
    "def execute_function_recommendation_for_more(_):\n",
    "    global multi_movie_df\n",
    "    with out_recommendation_for_more:\n",
    "          clear_output()\n",
    "          merge_movies()\n",
    "          create_cosine()\n",
    "          recommendation_titles = []\n",
    "          recommendation_list = get_top_list_for_more( len(multi_movie_df)-1, True, recommendations_for_more.value)\n",
    "          for movie in recommendation_list:\n",
    "            recommendation_titles.append(movie[0])\n",
    "          print(\"Recommendation(s):\")\n",
    "          display(showMovieInHtml(recommendation_titles))\n",
    "          multi_movie_df = movie_df[['Title','Plot','Writer']]\n",
    "            \n",
    "button_add_for_more.on_click(execute_function_add_for_more)\n",
    "button_remove_all_for_more.on_click(execute_function_remove_all_for_more)\n",
    "button_recommendation_for_more.on_click(execute_function_recommendation_for_more)\n",
    "out_add_for_more = widgets.Output()\n",
    "out_recommendation_for_more = widgets.Output()\n",
    "\n",
    "box_for_more = widgets.VBox([movies_for_more, button_add_for_more, button_remove_all_for_more, recommendations_for_more, button_recommendation_for_more, out_add_for_more, out_recommendation_for_more])\n",
    "box_for_more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation based on multiple movies\n",
    "\n",
    "The second and final approach was to make a recommendation for each film and then combine the recommendations at the end. Because each film in our case has the same weighting for the recommendations, the results can simply be added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sum_for_multi = np.array(0)\n",
    "selected_movies_for_multi = []\n",
    "\n",
    "movies_for_multi = widgets.Dropdown(\n",
    "    options=list(zip(df.Title, df.index)),\n",
    "    description='Select a movie:\\n ',\n",
    "    disabled=False,\n",
    "    layout={'width': 'max-content'}\n",
    ")\n",
    "button_add_for_multi = widgets.Button(\n",
    "    description='Add movie',\n",
    "    disabled=False,\n",
    ")\n",
    "button_remove_all_for_multi = widgets.Button(\n",
    "    description='Delete all selected movies',\n",
    "    disabled=False,\n",
    ")\n",
    "recommendations_for_multi = widgets.IntText(\n",
    "    min=0,\n",
    "    value=3,\n",
    "    description='Number of recommendations:\\n ',\n",
    "    disabled=False\n",
    ")\n",
    "merge_strategy_for_multi = widgets.RadioButtons(\n",
    "    options=[('Each matrix by itself',0), ('Sum matrix',1)],\n",
    "    description='Merge strategy:',\n",
    "    disabled=False\n",
    ")\n",
    "button_recommendation_for_multi = widgets.Button(\n",
    "    description='Recommendation',\n",
    "    disabled=False,\n",
    ")\n",
    "def get_top_list_for_multi(movieIds, number_of_recommendations=6):\n",
    "    top_list = []\n",
    "    for movieId in movieIds:\n",
    "        top_list = top_list + \\\n",
    "            recommendation(movieId,cosine_plot_tf,'tupel',number_of_recommendations) + \\\n",
    "            recommendation(movieId,cosine_plot_bow,'tupel',number_of_recommendations) + \\\n",
    "            recommendation(movieId,cosine_writer_tf,'tupel',number_of_recommendations) + \\\n",
    "            recommendation(movieId,cosine_writer_bow,'tupel',number_of_recommendations) + \\\n",
    "            recommendation(movieId,cosine_title_tf,'tupel',number_of_recommendations) + \\\n",
    "            recommendation(movieId,cosine_title_bow,'tupel',number_of_recommendations)\n",
    "    top_list = sorted(top_list, key=lambda x: x[1], reverse=True)\n",
    "    titles = []\n",
    "    back = []\n",
    "    for movie in top_list:\n",
    "        if movie[0] not in titles:\n",
    "            titles.append(movie[0])\n",
    "            back.append(movie)\n",
    "    return back[:number_of_recommendations]\n",
    "\n",
    "def get_top_list_from_sum_for_multi(movieIds, consine_sum, number_of_recommendations=6):\n",
    "    top_list = []\n",
    "    for movieId in movieIds:\n",
    "        top_list = top_list + \\\n",
    "                   recommendation(movieId, consine_sum, 'tupel', number_of_recommendations)\n",
    "    top_list = sorted(top_list, key=lambda x: x[1], reverse=True)\n",
    "    titles = []\n",
    "    back = []\n",
    "    for movie in top_list:\n",
    "        if movie[0] not in titles:\n",
    "            titles.append(movie[0])\n",
    "            back.append(movie)\n",
    "    return back[:number_of_recommendations]\n",
    "\n",
    "def execute_function_add_for_multi(_):\n",
    "    with out_add_for_multi:\n",
    "        clear_output()\n",
    "        if not movies_for_multi.value in selected_movies_for_multi:\n",
    "            selected_movies_for_multi.append(movies_for_multi.value)\n",
    "        movies_df_for_multi = []\n",
    "        for movie in selected_movies_for_multi:\n",
    "            movies_df_for_multi.append(df.iloc[movie])\n",
    "        print(\"Selected Movie(s):\")\n",
    "        display(HTML(movie_display.show(movies_df_for_multi)))\n",
    "\n",
    "def execute_function_remove_all_for_multi(_):\n",
    "    with out_add_for_multi:\n",
    "        clear_output()\n",
    "        selected_movies_for_multi.clear()\n",
    "\n",
    "def execute_function_recommendation_for_multi(_):\n",
    "    global cosine_sum_for_multi\n",
    "    with out_recommendation_for_multi:\n",
    "          clear_output()\n",
    "          recommendation_titles = []\n",
    "\n",
    "          if merge_strategy_for_multi.value == 0:\n",
    "              recommendation_list = get_top_list_for_multi(selected_movies_for_multi, recommendations_for_multi.value)\n",
    "          if merge_strategy_for_multi.value == 1:\n",
    "              if cosine_sum_for_multi.size == 1:\n",
    "                  cosine_sum_for_multi = calculate_cosine_sum([cosine_plot_tf, cosine_plot_bow, cosine_writer_tf, cosine_writer_bow, cosine_title_tf, cosine_title_bow])\n",
    "              recommendation_list = get_top_list_from_sum_for_multi(selected_movies_for_multi, cosine_sum_for_multi, recommendations_for_one.value)\n",
    "\n",
    "          for movie in recommendation_list:\n",
    "              recommendation_titles.append(movie[0])\n",
    "\n",
    "          print(\"Recommendation(s):\")\n",
    "          display(showMovieInHtml(recommendation_titles))\n",
    "\n",
    "button_add_for_multi.on_click(execute_function_add_for_multi)\n",
    "button_remove_all_for_multi.on_click(execute_function_remove_all_for_multi)\n",
    "button_recommendation_for_multi.on_click(execute_function_recommendation_for_multi)\n",
    "out_add_for_multi = widgets.Output()\n",
    "out_recommendation_for_multi = widgets.Output()\n",
    "\n",
    "box_for_multi = widgets.VBox([movies_for_multi, button_add_for_multi, button_remove_all_for_multi, merge_strategy_for_multi, recommendations_for_multi, button_recommendation_for_multi, out_add_for_multi, out_recommendation_for_multi])\n",
    "box_for_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fca98ced75e3b70b02ac3b0fddc14254b9e3b048d240659196fc27e019c1f4a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
