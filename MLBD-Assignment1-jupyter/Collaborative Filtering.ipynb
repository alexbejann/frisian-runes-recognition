{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering\n",
    "- Patrick Schaper (534366)\n",
    "- Daniel-Alexandru Bejan (474404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from movie_display import movie_display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis\n",
    "\n",
    "In this section of the notebook i am doing some analysis on the data to get to know the dataset better and get some more insights about the data and what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a dataframe\n",
    "movies = pd.read_csv('./dataset/movies.csv')\n",
    "links = pd.read_csv('./dataset/links.csv')\n",
    "ratings = pd.read_csv('./dataset/ratings.csv')\n",
    "tags = pd.read_csv('./dataset/tags.csv')\n",
    "df = pd.read_json('./dataset/imdbdata.json', orient='columns')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is to get some basic information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of ratings: {len(ratings)}\")\n",
    "print(f\"Number of unique movieId's: {ratings['movieId'].nunique()}\")\n",
    "print(f\"Number of unique users: {ratings['userId'].nunique()}\")\n",
    "print(f\"Average number of ratings per user: {round(len(ratings)/ratings['userId'].nunique(), 2)}\")\n",
    "print(f\"Average number of ratings per movie: {round(len(ratings)/ratings['movieId'].nunique(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"rating\", data=ratings)\n",
    "plt.title(\"Distribution of movie ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to find out in this section with is the global mean rating and the mean rating for user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean global rating: {round(ratings['rating'].mean(),2)}.\")\n",
    "\n",
    "mean_ratings = ratings.groupby('userId')['rating'].mean()\n",
    "print(f\"Mean rating per user: {round(mean_ratings.mean(),2)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the lowest rated movie, which for some reason is the \"Santa with Muscles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = ratings.groupby('movieId')[['rating']].mean()\n",
    "lowest_rated = mean_ratings['rating'].idxmin()\n",
    "movies[movies['movieId'] == lowest_rated]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the highest rated movie is \"Lamerica\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rated = mean_ratings['rating'].idxmax()\n",
    "movies[movies['movieId'] == highest_rated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_stats = ratings.groupby('movieId')[['rating']].agg(['count', 'mean'])\n",
    "movie_stats.columns = movie_stats.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = movie_stats['count'].mean()\n",
    "# m = movie_stats['mean'].mean()\n",
    "\n",
    "# def bayesian_avg(ratings):\n",
    "#     bayesian_avg = (C*m+ratings.sum())/(C+ratings.count())\n",
    "#     return bayesian_avg\n",
    "\n",
    "# bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
    "# bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
    "# movie_stats = movie_stats.merge(bayesian_avg_ratings, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_stats = movie_stats.merge(movies[['movieId', 'title']])\n",
    "# movie_stats.sort_values('bayesian_avg', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_stats.sort_values('bayesian_avg', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# movies['genres'] = movies['genres'].apply(lambda x: x.split(\"|\"))\n",
    "# movies.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_frequency = Counter(g for genres in movies['genres'] for g in genres)\n",
    "\n",
    "print(f\"There are {len(genre_frequency)} genres.\")\n",
    "\n",
    "genre_frequency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the top 5 most common genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 5 most common genres: \\n\", genre_frequency.most_common(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-item matrix\n",
    "After analizing the dataset a little we are constructing the User-Item matrix and we start calculating the similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table with userId as the index, movieId as the columns, and rating as the values\n",
    "user_item_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity metrics\n",
    "\n",
    "This section is about the similarity metrics that we are going to use to calculate the similarities between the users and the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(df, similarity='none'):\n",
    "    \"\"\"\n",
    "    Prepare the datafram for the cosine similarity\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas Dataframe\n",
    "    similarity : string\n",
    "    Returns\n",
    "    -------\n",
    "     dataframe : Pandas dataframe\n",
    "    \"\"\"\n",
    "    if similarity == 'pearson':\n",
    "        # centered zero matrix\n",
    "        # From slides: Subtract the mean (average) user rating from each user’s rating\n",
    "        # (substracts the ROW mean)\n",
    "        # 1. Subtract the average of a user from its ratings\n",
    "        # 2. The negative values represent negative ratings, positive values represent positive ratings\n",
    "        # 3. The value 0 is now the average rating for a user\n",
    "        similarity_matrix = df.subtract(df.mean(axis=1), axis=0)   \n",
    "    if similarity == 'adjusted':\n",
    "        # Adjusted cosine similarity\n",
    "        # Per slides: Subtract the average item rating from each user rating for a given item (when\n",
    "        # we calculate the difference between users)\n",
    "        # (substracts the COLUMN mean)\n",
    "        similarity_matrix = (df - df.mean())\n",
    "    # From slides: \n",
    "    # Problem: low ratings and high ratings will have the same angle when\n",
    "    # calculating the cosine similarity\n",
    "    # ▪ Difference between A and B and A and C is small, whereas A and C are\n",
    "    # almost opposite users\n",
    "    # ▪ Solution: center around 0\n",
    "    # Therefore we have to center everything around 0 filling the NaN values with 0. as follows\n",
    "    similarity_matrix = df.fillna(0)\n",
    "    # Calculating the cosine similarity\n",
    "    similarity = cosine_similarity(similarity_matrix)\n",
    "    # set the columns and index of the initial dataframe otherwise it would messup the indexes later\n",
    "    return pd.DataFrame(similarity,index=df.index, columns=df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate similarity matrixes\n",
    "\n",
    "Here we test our similarity matrix calculation functions and we are going to use them later on in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_matrix = calculate_similarity(user_item_matrix)\n",
    "\n",
    "pearson_similarity_matrix = calculate_similarity(user_item_matrix, 'pearson')\n",
    "\n",
    "ajusted_cosine_similarity_matrix = calculate_similarity(user_item_matrix, 'adjusted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for each similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine similarity\n",
    "cosine_similarity_matrix = calculate_similarity(user_item_matrix)\n",
    "# calc pearson similarity\n",
    "pearson_similarity_matrix = calculate_similarity(user_item_matrix, 'pearson')\n",
    "# calculate adjusted cosine similarity\n",
    "adjusted_cosine_similarity_matrix = calculate_similarity(user_item_matrix, 'adjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(cosine_similarity_matrix, cmap='viridis')\n",
    "# sns.heatmap(pearson_similarity_matrix, cmap='viridis')\n",
    "# sns.heatmap(ajusted_cosine_similarity_matrix, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-user recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the user-item matrix to user-user matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is just a testing that we have used to check the user-item matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1\n",
    "user_row = cosine_similarity_matrix.loc[1]\n",
    "\n",
    "updated_df = user_row.drop(1)\n",
    "updated_df.head()\n",
    "updated_df.sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below is used to get the top 10 similar users for a given user_id and user_item matrix as well as the similarity strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(user_id, user_item_matrix, similarity_strategy='none'):\n",
    "    \"\"\"\"Create a dict with the most similar users and ranks them based on similarity \"\"\"\n",
    "    # get the similarity matrix based similarity strategy\n",
    "    similarity_matrix = calculate_similarity(user_item_matrix, similarity_strategy)\n",
    "    # drop the user itself\n",
    "    similar_users = (similarity_matrix.loc[user_id]).drop(1)\n",
    "    # sorting the value descending in order to get the most similar users first\n",
    "    return similar_users.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing the method above\n",
    "# # user_id= 2\n",
    "# similar_users = get_similar_users(2)\n",
    "\n",
    "# similar_users\n",
    "\n",
    "# # print(similar_users.index.to_list)\n",
    "\n",
    "\n",
    "# # user_item_matrix.loc[similar_users.index]\n",
    "\n",
    "# # for user_id, similarity in pd.DataFrame(similar_users).iterrows():\n",
    "# #     print(user_id)\n",
    "#     # simlar_user = user_item_matrix.iloc[user_id].dropna()\n",
    "#     # print(simlar_user)\n",
    "\n",
    "# # users_movies = pd.DataFrame(user_item_matrix.iloc[lambda x: x % 2 == 0])\n",
    "# # print(type(users_movies.columns)) \n",
    "# # droplist = [column for column in users_movies if 1 >= column <= 5]\n",
    "# # print(droplist)\n",
    "# # dropped_columns = users_movies.drop(droplist,inplace=True)\n",
    "\n",
    "# # dropped_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_list(user_id, number_of_recommendations, similarity_strategy, debug=False):\n",
    "    # get the similar users with the selected similarity strategy as pandas dataframe\n",
    "    similar_user_data = get_similar_users(user_id, user_item_matrix, similarity_strategy)\n",
    "\n",
    "    # print(similar_users)\n",
    "    # get pandas dataframe with each users and their movies\n",
    "    rated_movies_by_user = user_item_matrix.loc[user_id].dropna()\n",
    "    # users_movies = pd.DataFrame(user_item_matrix.iloc[2])\n",
    "    recommendations = []\n",
    "    for user_id, similarity in similar_user_data.items():\n",
    "        # select the user from the user_item matrix and drop the null values\n",
    "        similar_user_movies = user_item_matrix.loc[user_id].dropna()\n",
    "        # print('current user',similar_user_movies.tolist())\n",
    "        for movie_id, rating in similar_user_movies.items():\n",
    "            if movie_id not in rated_movies_by_user:\n",
    "                # print('user_id', user_id, 'movie', movie_id, 'similarity',similarity, 'rating', rating)\n",
    "                recommendations.append((movie_id, rating * similarity))\n",
    "    # sort values descending\n",
    "    # recommendations = initial_recommendation.sort_values(ascending=False).head(number_of_recommendations)\n",
    "    # # return the movies id only\n",
    "    # print(recommendations[:30])\n",
    "    recommendations.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    # print(recommendations[:10])\n",
    "    if (debug):\n",
    "        print(len(recommendations))\n",
    "        print(recommendations[:10])\n",
    "    movies = []\n",
    "    # put the movie ids into a list to be prepared for display in the notebook widgets\n",
    "    for movie_id, _ in recommendations:\n",
    "        movies.append(movie_id)\n",
    "    \n",
    "    return movies[:number_of_recommendations]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we are getting for user_id, and with the default cosine similarity.\n",
    "Observing the results we can see the the method is working as expected. Giving us the top 5 movies with their similarities score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation_list(2, 5, 'none', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-item recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select a user\n",
    "2. Select the movies that the user has rated more than 3.5 stars\n",
    "3. Based on the user "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give N (configurable) recommendations for a given user U (configurable) based on the\n",
    "movies the user U rated with at least 3.5 stars. Explain your implementation and the\n",
    "strategy that you use for selecting the final recommendations.\n",
    "Which means that we have to give the user N number of recommendations for a certain user(selectable) from the movies that he has rated with at least 3.5 stars.\n",
    "\n",
    "In the UI we would have to:\n",
    "1. N number of recommendations\n",
    "2. U which user id\n",
    "3. Select certain movie which is rated >= 3.5 stars\n",
    "\n",
    "How to do the recommendations:\n",
    "1. find similar items\n",
    "2. Candidate selection (items you might recommend)\n",
    "3. Score recommendation candidates\n",
    "4. Filter candidates (top_n) recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create item_user matrix\n",
    "# The difference between the user_item matrix is that the movie id will be the index and the columns would be the user id\n",
    "# Which means that when we calculated the similarity matrix we would calculate the mean and using the ratings from the users \n",
    "# Per slides: Both(pearson and adjusted cosine similarity) are applicable for user-user and item-item recommendations\n",
    "# Simply switch around users and items in the formulas!\n",
    "item_user_matrix = ratings.pivot_table(index='movieId', columns='userId', values='rating')\n",
    "\n",
    "item_user_matrix.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the similarity matrixes\n",
    "\n",
    "once again but now using the item_user_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "item_item_cosine_similarity_matrix = calculate_similarity(item_user_matrix)\n",
    "# calc pearson similarity\n",
    "item_item_pearson_similarity_matrix = calculate_similarity(item_user_matrix, 'pearson')\n",
    "# calculate adjusted cosine similarity\n",
    "item_item_adjusted_cosine_similarity_matrix = calculate_similarity(item_user_matrix, 'adjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_pearson_similarity_matrix.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each similar item that has not been seen by the user, calculate the expected rating\n",
    "Using the similarity matrixes \n",
    "\n",
    "In order to predict the rating we have to know the following and use the matrixes\n",
    "We have to know the movie id to which we want to predict and the user id as well\n",
    "\n",
    "Following we need the similarity matrix to find similar items and the item_user matrix\n",
    "Prediction formula used is:\n",
    "\n",
    "R(m, u) = {∑ ⱼ S(m, j)R(j, u)}/ ∑ ⱼ S(m, j)\n",
    "R(m, u): the rating for movie m by user u\n",
    "S(m, j): the similarity between movie m and movie j\n",
    "j ∈ J where J is the set of the similar movies to movie m\n",
    "\n",
    "source: https://medium.com/@Sumeet_Agrawal/item-based-collaborative-filtering-4e64f65ae6ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_prediction(movie_id, user_id, user_item_matrix, similarity_matrix, debug=False):\n",
    "    # rating from the user \n",
    "    # contains movie_id and the rating\n",
    "    user_rating = user_item_matrix.loc[:, user_id].sort_values(ascending=False).dropna()\n",
    "    # print('rating from user',user_rating)\n",
    "    # the weights for our calculation\n",
    "    # We look at the similarities between movie_id and the other movies \n",
    "    # and we sort and descending and pick 10 most similar items\n",
    "    similarity_items_by_id = similarity_matrix.loc[movie_id][user_rating.index]\n",
    "    # get the items that have a similarity greater than 0\n",
    "    similarity_items_by_id = similarity_items_by_id[similarity_items_by_id > 0]\n",
    "    # print('similar items by id',similarity_items_by_id)\n",
    "    # as the weights sum to zero, can't be normalized\n",
    "    if similarity_items_by_id.sum() == 0:\n",
    "        # we have to calculate the mean of the user ratings and return it \n",
    "        return round(user_rating.mean(), 1)\n",
    "\n",
    "    weighted_average = np.average(user_rating.loc[similarity_items_by_id.index], weights = similarity_items_by_id)\n",
    "    # https://towardsdatascience.com/3-ways-to-compute-a-weighted-average-in-python-4e066de7a719\n",
    "    predicted_rating = round(weighted_average, 1)\n",
    "    if (debug):\n",
    "        print('predicted', predicted_rating)\n",
    "        print('user ratings', user_rating.loc[similarity_items_by_id.index])\n",
    "        print('similar items by id',similarity_items_by_id)\n",
    "    return predicted_rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again testing the rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id 1208 user_id 571 expected  3.5\n",
    "rating_prediction(1208, 571, item_user_matrix, item_item_pearson_similarity_matrix, debug=True)\n",
    "rating_prediction(2, 4, user_item_matrix, item_item_pearson_similarity_matrix, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies_by_item(user_id, number_of_recommendations, item_user_matrix, user_item_matrix, similarity_matrix, debug=False):\n",
    "   \"\"\"\n",
    "    Recommend Movies for a user, used for Item-Item\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_id : integer\n",
    "    number_of_recommendations : integer\n",
    "    item_user_matrix : Pandas dataframe\n",
    "    user_item_matrix : Pandas dataframe\n",
    "    similarity_matrix : Pandas dataframe\n",
    "    debug : boolean False as default\n",
    "    Returns\n",
    "    -------\n",
    "     recommendation_list : [(movie_id, predicted_rating)]\n",
    "    \"\"\"\n",
    "   # 1. Take the k highest rated items of a user, for this we need the ones with more than 3.5\n",
    "   highest_rated_items = user_item_matrix.loc[user_id].loc[lambda rating : rating >= 3.5].sort_values(ascending=False)\n",
    "   # Filter ones rated with more than 3.5\n",
    "   # highest_rated_items.loc[lambda rating : rating >= 1]\n",
    "   # 2. Find j similar items to those k highest rated items\n",
    "   similar_items_to_highest_items = similarity_matrix.loc[highest_rated_items.index]\n",
    "   if debug:\n",
    "      print('highest rated items index, which is the id of the movie',highest_rated_items.index)\n",
    "      print('highest rated items', highest_rated_items)\n",
    "      print('similar items', similar_items_to_highest_items)\n",
    "   # 3. For each similar item that has not been seen by the user, calculate the expected rating\n",
    "   # checking if the value is NaN by checking if it's equals to itself https://stackoverflow.com/a/944712\n",
    "   unrated_items_by_user = user_item_matrix.loc[user_id].loc[lambda rating : rating != rating]\n",
    "   if debug:\n",
    "      print('unrated movies', unrated_items_by_user)\n",
    "   recommendation_list = []\n",
    "   for movie_id, _ in unrated_items_by_user.items():\n",
    "      # print('movie_id', movie_id)\n",
    "      predicted_rating = rating_prediction(movie_id, user_id, user_item_matrix, similarity_matrix)\n",
    "      recommendation_list.append((movie_id, predicted_rating))\n",
    "   # 4. Select the top n movies with the highest rating\n",
    "   recommendation_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "   return recommendation_list[:number_of_recommendations]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the method above to see if it works by using the user_id 5 with the pearson similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_movies_by_item(5, 3, item_user_matrix, user_item_matrix, item_item_pearson_similarity_matrix, debug=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "Possible validation methods:\n",
    "- RMSE\n",
    "- Hit-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hit_rate(test_dataframe, train_dataframe,similarity_matrix, debug=False):\n",
    "    # User-User\n",
    "    # Initialize the hit rate\n",
    "    hit_rate = 0\n",
    "    # Iterate over the users in the test set\n",
    "    # print(test_df.index)\n",
    "    # print(test_df.columns)\n",
    "    # print('train', train_df)\n",
    "    for movie_id, row in test_dataframe.iterrows():\n",
    "        # print(type(row))\n",
    "        for user_id, rating in row.items():\n",
    "            # Select the row in the similarity matrix corresponding to the user\n",
    "            user_row = similarity_matrix.loc[user_id]\n",
    "            # Select the top N most similar users\n",
    "            N = 10\n",
    "            similar_users = user_row.sort_values(ascending=False).head(N)\n",
    "            # print(similar_users)\n",
    "            # Extract the user ids of the similar users\n",
    "            similar_user_ids = similar_users.index\n",
    "            # print(similar_user_ids)\n",
    "            # Select the rows of the user-item matrix corresponding to the similar users\n",
    "            print(similar_user_ids)\n",
    "            similar_user_rows = train_dataframe[train_dataframe.isin(similar_user_ids)]\n",
    "\n",
    "            # similar_user_rows = train_df.loc[similar_user_ids]\n",
    "            # print(similar_user_rows)\n",
    "            # Check if the recommended item is present in the test set for the user\n",
    "            # print('hit rate', movie_id, 'hit2 ', similar_user_rows.columns)\n",
    "            if movie_id in similar_user_rows.columns:\n",
    "                hit_rate += 1\n",
    "    # Calculate the hit rate\n",
    "    hit_rate /= test_dataframe.shape[0]\n",
    "    return hit_rate\n",
    "    # Calculate the hit rate\n",
    "    # hit_rate /= test_df.shape[0]\n",
    "    # print(f' User-user Hit rate: {hit_rate:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hit_rate_v2(user_item_matrix, similarity_matrix, debug=False):\n",
    "    # User-User\n",
    "    # 1. For each user, leave one high rating out (store this rating in a test set)\n",
    "    hit_rate = 0\n",
    "    N = 10\n",
    "    user_number = len(user_item_matrix)\n",
    "    for user_id, values in user_item_matrix.iterrows():\n",
    "        # print('values', values)\n",
    "        highest_rating = values.sort_values(ascending=False).index[0]\n",
    "        # 2. Recommend n movies\n",
    "        user_recommendations = get_user_reccommendations(user_id, 10, similarity_matrix)\n",
    "        # 3. If the \"left-out\"-movie is part of your recommendation, you've got a hit!\n",
    "        # print('user_recommendations', user_recommendations)\n",
    "        # 3. If the \"left-out\"-movie is part of your recommendation, you've got a hit!\n",
    "        if debug:\n",
    "            print('checking',movie_id , user_recommendations)\n",
    "        for movie_id ,rating in user_recommendations:\n",
    "            if highest_rating == rating:\n",
    "                hit_rate += 1\n",
    "    return hit_rate / float(user_number)\n",
    "# print('User-user Hit rate:', hit_rate / float(user_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(user_item_matrix, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-User Hit-rate validation\n",
    "# Split the data into a training set and a test set\n",
    "# train_df, test_df = train_test_split(user_item_df, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE\n",
    "\n",
    "1. Remove some test data from the dataset (remove those ratings from the training set)\n",
    "2. Predict ratings for the missing items\n",
    "3. Compare to the real values in the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(test_dataframe, item_user_matrix, similarity_matrix):\n",
    "    # Initialize the list of squared differences\n",
    "    squared_differences = []\n",
    "    # Iterate over the user-item pairs in the test set\n",
    "    for user_id, row in test_df.iterrows():\n",
    "        for movie_id in row.index:\n",
    "            # Check if the row value is nana if so continue\n",
    "            if (row[movie_id] != row[movie_id]):\n",
    "                continue\n",
    "            # Calculate the predicted rating\n",
    "            predicted_rating = rating_prediction(movie_id, user_id, item_user_matrix, similarity_matrix)\n",
    "            # print('movie_id', movie_id, 'user_id', user_id, 'expected ', row[movie_id],'predicted',predicted_rating)\n",
    "            # Calculate the squared difference between the predicted and actual rating\n",
    "            squared_differences.append((predicted_rating - row[movie_id]) ** 2)\n",
    "\n",
    "    # Calculate the MSE as the average of the squared differences\n",
    "    mse = np.mean(squared_differences)\n",
    "    # Calculate the RMSE as the square root of the MSE\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(user_item_matrix, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(user_item_matrix, test_size=0.1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on average this runs in 1.5 minutes\n",
    "rmse_item_item_cosine = calculate_rmse(test_df, item_user_matrix, item_item_cosine_similarity_matrix)\n",
    "rmse_item_item_pearson = calculate_rmse(test_df, item_user_matrix, item_item_pearson_similarity_matrix)\n",
    "rmse_item_item_adjusted = calculate_rmse(test_df, item_user_matrix, item_item_adjusted_cosine_similarity_matrix)\n",
    "\n",
    "print(f'RMSE Cosine: {rmse_item_item_cosine:.2f}')\n",
    "print(f'RMSE Pearson: {rmse_item_item_pearson:.2f}')\n",
    "print(f'RMSE Adjusted: {rmse_item_item_adjusted:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widgets implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(imdb_id=[]):\n",
    "    movies = []\n",
    "    for x in range(len(imdb_id)):\n",
    "        movieIndex = df.loc[df['imdbId'] == imdb_id[x]].index[0]\n",
    "        movies.append(df.iloc[movieIndex])\n",
    "    \n",
    "    return movies\n",
    "\n",
    "def displayRecommendations(recommendations=[]):\n",
    "    movies = []\n",
    "    for _, row in links.iterrows():\n",
    "        if row['movieId'] in recommendations:\n",
    "            movies.append(int(row['imdbId']))\n",
    "    \n",
    "    return get_indexes(movies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a test for the movies display method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(displayRecommendations([589, 1196]))\n",
    "\n",
    "recommendations = displayRecommendations([337, 318, 21])\n",
    "print(type(recommendations)) \n",
    "HTML(movie_display.show(recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_user_recommendations(selected_user, recommendations, similarity_strategy):\n",
    "    if similarity_strategy == 0:\n",
    "        recommendation_list = get_recommendation_list(selected_user, recommendations, similarity_strategy='none')\n",
    "    if similarity_strategy == 1:\n",
    "        recommendation_list = get_recommendation_list(selected_user, recommendations, similarity_strategy='pearson')\n",
    "    if similarity_strategy == 2:\n",
    "        recommendation_list = get_recommendation_list(selected_user, recommendations, similarity_strategy='adjusted')\n",
    "\n",
    "    return recommendation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_user_recommendations(2,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_item_recommendations(selected_user, recommendations, similarity_strategy):\n",
    "    if similarity_strategy == 0:\n",
    "        recommendation_list = get_recommendation_list(selected_user, recommendations, similarity_strategy='none')\n",
    "    if similarity_strategy == 1:\n",
    "        recommendation_list = get_recommendation_list(selected_user, recommendations, similarity_strategy='pearson')\n",
    "    if similarity_strategy == 2:\n",
    "        recommendation_list = get_recommendation_list(selected_user, recommendations, similarity_strategy='adjusted')\n",
    "\n",
    "    return recommendation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_recommendations(2, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display_functions import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "selected_user = widgets.Dropdown(\n",
    "    options=list(x+1 for x in range(ratings['userId'].nunique())),\n",
    "    description='Select a user:\\n ',\n",
    "    disabled=False,\n",
    "    layout={'width': 'max-content'}\n",
    ")\n",
    "recommendations = widgets.IntText(\n",
    "    min=0,\n",
    "    value=3,\n",
    "    description='Number of recommendations:\\n ',\n",
    "    disabled=False,\n",
    ")\n",
    "recommendation_method = widgets.RadioButtons(\n",
    "    options=[('User-User',0), ('Item-Item',1)],\n",
    "    description='Recommendation:',\n",
    "    disabled=False\n",
    ")\n",
    "similarity_strategy = widgets.RadioButtons(\n",
    "    options=[('Cosine',0), ('Pearson',1), ('Adjusted cosine',2)],\n",
    "    description='Similarity metrics:',\n",
    "    disabled=False\n",
    ")\n",
    "button = widgets.Button(\n",
    "    description='Recommendation',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def execute_function(_):\n",
    "    with out:\n",
    "          clear_output()\n",
    "          recommendation_list = []\n",
    "          print(recommendation_method)\n",
    "          if recommendation_method.value == 0:\n",
    "            recommendation_list = user_user_recommendations(selected_user.value, recommendations.value, similarity_strategy.value)\n",
    "          if recommendation_method.value == 1:\n",
    "            recommendation_list = item_item_recommendations(selected_user.value, recommendations.value, similarity_strategy.value)\n",
    "          print(f'Selected User: {selected_user.value}')\n",
    "            \n",
    "          print('Recommendation(s):')\n",
    "          print(f'Got movies with the following ids as recommendations: {recommendation_list}')\n",
    "          display(HTML(movie_display.show(displayRecommendations(recommendation_list))))\n",
    "            \n",
    "button.on_click(execute_function)\n",
    "out = widgets.Output()\n",
    "\n",
    "box = widgets.VBox([recommendations, selected_user, recommendation_method, similarity_strategy, button, out])\n",
    "box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "53a1c45876d37b93742cefcbccd0e028309dbdecc6e457f55650f19fbe3f8ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
